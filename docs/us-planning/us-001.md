# Planificaci√≥n US-001: Configuraci√≥n del Entorno Local Robusto

> **Estado:** üìã Planificaci√≥n
> **Sprint:** 1 - Fundamentos y Adquisici√≥n de Datos
> **Puntos de Historia:** 3 (6 horas estimadas)
> **Fecha de Planificaci√≥n:** 2025-11-26

---

## üìã Historia de Usuario

**Como** desarrollador
**Quiero** un entorno de desarrollo local aislado y reproducible
**Para** trabajar eficientemente con soporte GPU nativo sin overhead de virtualizaci√≥n

---

## ‚úÖ Criterios de Aceptaci√≥n

- [ ] Repositorio Git inicializado con estructura de proyecto basada en Cookiecutter Data Science
- [ ] Entorno Python 3.11 gestionado con Poetry (compatible con Poetry en Python 3.12.6 del host)
- [ ] Drivers NVIDIA y CUDA Toolkit verificados en host (Windows 11)
- [ ] PyTorch 2.9.1 con CUDA 13.0 reconoce `cuda:0` nativamente
- [ ] `docker-compose.yml` para servicios auxiliares (MLflow, Dagster)
- [ ] README con instrucciones de setup completas
- [ ] Pre-commit hooks configurados (Ruff, Black, MyPy)
- [ ] Estructura de directorios conforme a AGENTS.md y proyecto Geo-Rect

---

## üèóÔ∏è Plan de Implementaci√≥n

### Fase 1: Verificaci√≥n de Prerrequisitos del Sistema (30 min)

#### 1.1 Verificar instalaci√≥n de NVIDIA y CUDA
```powershell
# Verificar drivers NVIDIA
nvidia-smi

# Verificar versi√≥n de CUDA
nvcc --version
```

**Requisitos m√≠nimos:**
- NVIDIA Driver >= 525.x (para CUDA 12.x)
- CUDA Toolkit 12.4 instalado
- RTX 4070 Laptop (8GB VRAM) detectada

#### 1.2 Verificar Python y Poetry
```powershell
# Verificar Python del sistema (donde est√° Poetry)
python --version  # Esperado: 3.12.6

# Verificar Poetry
poetry --version  # Esperado: >= 1.7.0
```

---

### Fase 2: Estructura del Proyecto con Cookiecutter (45 min)

#### 2.1 Estructura de Directorios Adaptada

Basada en [Cookiecutter Data Science](https://cookiecutter.io/) pero adaptada para el proyecto Geo-Rect:

```
geo-rect/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci.yml                    # GitHub Actions CI/CD
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Datos originales (DVC tracked)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ satellite_tiles/          # Im√°genes de Google Maps
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vectors/                  # GeoJSON originales
‚îÇ   ‚îú‚îÄ‚îÄ processed/                    # Datos preprocesados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aligned/                  # Im√°genes alineadas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ features/                 # Features extra√≠dos
‚îÇ   ‚îú‚îÄ‚îÄ labeled/                      # 300 manzanas etiquetadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ val/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îú‚îÄ‚îÄ models/                           # Modelos entrenados (DVC tracked)
‚îÇ   ‚îú‚îÄ‚îÄ dinov2/                       # Cache DINOv2
‚îÇ   ‚îú‚îÄ‚îÄ loftr/                        # Pesos LoFTR
‚îÇ   ‚îî‚îÄ‚îÄ xgboost/                      # Modelos XGBoost
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ exploratory/                  # EDA y an√°lisis (texto en espa√±ol)
‚îÇ   ‚îî‚îÄ‚îÄ experimental/                 # Experimentos
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ acquisition/                  # Fase 1: Descarga de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ google_maps_client.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tile_stitcher.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_rasterizer.py
‚îÇ   ‚îú‚îÄ‚îÄ alignment/                    # Fase 2: Alineaci√≥n CV
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ecc_aligner.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loftr_aligner.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sam_validator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cascade.py
‚îÇ   ‚îú‚îÄ‚îÄ classification/               # Fase 3: Clasificaci√≥n ML
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dino_extractor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_builder.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ensemble.py
‚îÇ   ‚îú‚îÄ‚îÄ api/                          # FastAPI endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas/
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/                    # Dagster pipelines
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/                        # Utilidades compartidas
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py
‚îÇ       ‚îú‚îÄ‚îÄ logging.py
‚îÇ       ‚îî‚îÄ‚îÄ geo.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ e2e/
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ referencia/
‚îÇ   ‚îú‚îÄ‚îÄ us-planning/
‚îÇ   ‚îî‚îÄ‚îÄ us-resolved/
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                    # Imagen de producci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml            # Servicios auxiliares
‚îú‚îÄ‚îÄ scripts/                          # Scripts de utilidad
‚îÇ   ‚îî‚îÄ‚îÄ verify_cuda.py
‚îú‚îÄ‚îÄ .dvc/                             # Configuraci√≥n DVC
‚îú‚îÄ‚îÄ .pre-commit-config.yaml
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ dvc.yaml
‚îú‚îÄ‚îÄ AGENTS.md
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ STRUCTURE.md
```

---

### Fase 3: Configuraci√≥n de Poetry y Dependencias (1 hora)

#### 3.1 Inicializaci√≥n del Proyecto Poetry

```powershell
# Navegar al directorio del proyecto
cd c:\Users\arthu\Proyectos\INE\manzanasDispares

# Inicializar Poetry con Python 3.11 espec√≠fico
poetry init --name "geo-rect" --description "Sistema H√≠brido de Validaci√≥n Geoespacial" --author "Arthur Zizumbo" --python ">=3.11,<3.13"
```

#### 3.2 Dependencias Core

**pyproject.toml - Secci√≥n de dependencias:**

```toml
[tool.poetry]
name = "geo-rect"
version = "0.1.0"
description = "Sistema H√≠brido de Validaci√≥n Geoespacial con CV + ML"
authors = ["Arthur Zizumbo"]
readme = "README.md"
packages = [{include = "src"}]

[tool.poetry.dependencies]
python = ">=3.11,<3.13"

# Deep Learning - PyTorch 2.9.1 con CUDA 13.0
torch = {version = "2.5.1+cu124", source = "pytorch"}
torch = {version = "^2.9.1", source = "pytorch_cu130"}

torchvision = {version = "0.24.1+cu130", source = "pytorch"}

# Computer Vision
opencv-python = "^4.9.0"
kornia = "^0.7.3"
pillow = "^10.4.0"
scikit-image = "^0.24.0"

# Geospatial
geopandas = "^1.0.1"
shapely = "^2.0.6"
rasterio = "^1.4.2"
pyproj = "^3.7.0"
fiona = "^1.10.1"

# Machine Learning
xgboost = "^2.1.2"
lightgbm = "^4.5.0"
scikit-learn = "^1.5.2"
optuna = "^4.0.0"
shap = "^0.46.0"

# Embeddings & Transformers
transformers = "^4.46.2"
timm = "^1.0.11"

# Data Processing
polars = "^1.13.1"
pyarrow = "^18.0.0"

# MLOps
dvc = {extras = ["gs"], version = "^3.56.0"}
mlflow = "^2.18.0"
dagster = "^1.9.2"
dagster-webserver = "^1.9.2"
evidently = "^0.4.45"

# API
fastapi = "^0.115.5"
uvicorn = {extras = ["standard"], version = "^0.32.1"}
pydantic = "^2.9.2"
pydantic-settings = "^2.6.1"

# Utilities
python-dotenv = "^1.0.1"
httpx = "^0.27.2"
diskcache = "^5.6.3"
tqdm = "^4.67.0"
loguru = "^0.7.2"

[tool.poetry.group.dev.dependencies]
pytest = "^8.3.3"
pytest-cov = "^6.0.0"
pytest-asyncio = "^0.24.0"
ruff = "^0.7.4"
black = "^24.10.0"
mypy = "^1.13.0"
pre-commit = "^4.0.1"
ipykernel = "^6.29.5"
jupyter = "^1.1.1"
nbformat = "^5.10.4"

[[tool.poetry.source]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cu130"
priority = "explicit"

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP", "B", "C4", "SIM"]
ignore = ["E501"]

[tool.black]
line-length = 100
target-version = ["py311"]

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=src --cov-report=html --cov-report=term-missing"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
```

#### 3.3 Instalaci√≥n de Dependencias

```powershell
# Crear entorno virtual con Python 3.11
poetry env use python3.11

# Instalar todas las dependencias
poetry install --with dev

# Verificar instalaci√≥n de PyTorch con CUDA
poetry run python -c "import torch; print(f'PyTorch {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')"
```

**Salida esperada:**
```
PyTorch 2.5.1+cu124
CUDA available: True
CUDA version: 12.4
Device: NVIDIA GeForce RTX 4070 Laptop GPU
```

---

### Fase 4: Configuraci√≥n de Pre-commit Hooks (30 min)

#### 4.1 Archivo `.pre-commit-config.yaml`

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.6.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-json
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-merge-conflict

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.7.4
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format

  - repo: https://github.com/psf/black
    rev: 24.10.0
    hooks:
      - id: black
        language_version: python3.11

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.13.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
        args: [--ignore-missing-imports]
```

#### 4.2 Instalaci√≥n de Pre-commit

```powershell
poetry run pre-commit install
poetry run pre-commit run --all-files
```

---

### Fase 5: Docker Compose para Servicios Auxiliares (1 hora)

#### 5.1 Archivo `docker/docker-compose.yml`

```yaml
version: '3.8'

services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: geo-rect-mlflow
    ports:
      - "5020:5020"
    volumes:
      - mlflow-data:/mlflow
      - ../models:/models
    environment:
      - MLFLOW_TRACKING_URI=sqlite:///mlflow/mlflow.db
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5020
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5020/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  dagster:
    image: dagster/dagster-k8s:1.9.2
    container_name: geo-rect-dagster
    ports:
      - "3000:3000"
    volumes:
      - ../src/pipelines:/opt/dagster/app/pipelines
      - dagster-data:/opt/dagster/dagster_home
    environment:
      - DAGSTER_HOME=/opt/dagster/dagster_home
    command: dagster-webserver -h 0.0.0.0 -p 3000
    depends_on:
      - mlflow

volumes:
  mlflow-data:
  dagster-data:

networks:
  default:
    name: geo-rect-network
```

#### 5.2 Comandos de Docker

```powershell
# Levantar servicios
docker-compose -f docker/docker-compose.yml up -d

# Verificar estado
docker-compose -f docker/docker-compose.yml ps

# Ver logs
docker-compose -f docker/docker-compose.yml logs -f mlflow

# Detener servicios
docker-compose -f docker/docker-compose.yml down
```

---

### Fase 6: Scripts de Verificaci√≥n (30 min)

#### 6.1 Script `scripts/verify_cuda.py`

```python
"""
Script to verify CUDA installation and GPU availability.

This script checks the NVIDIA GPU, CUDA toolkit, and PyTorch CUDA support.
"""

import subprocess
import sys


def check_nvidia_smi() -> bool:
    """Check NVIDIA driver installation via nvidia-smi."""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=name,memory.total,driver_version", "--format=csv"],
            capture_output=True,
            text=True,
            check=True,
        )
        print("NVIDIA Driver Information:")
        print(result.stdout)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        print(f"nvidia-smi failed: {e}")
        return False


def check_pytorch_cuda() -> bool:
    """Check PyTorch CUDA support."""
    try:
        import torch

        print(f"PyTorch Version: {torch.__version__}")
        print(f"CUDA Available: {torch.cuda.is_available()}")

        if torch.cuda.is_available():
            print(f"CUDA Version: {torch.version.cuda}")
            print(f"cuDNN Version: {torch.backends.cudnn.version()}")
            print(f"Device Count: {torch.cuda.device_count()}")

            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"\nDevice {i}: {props.name}")
                print(f"  Memory: {props.total_memory / 1024**3:.2f} GB")
                print(f"  Compute Capability: {props.major}.{props.minor}")

            # Test tensor operation on GPU
            x = torch.randn(1000, 1000, device="cuda")
            y = torch.matmul(x, x)
            print(f"\nGPU Tensor Test: PASSED (result shape: {y.shape})")
            return True
        else:
            print("CUDA is not available")
            return False
    except ImportError:
        print("PyTorch is not installed")
        return False


def check_kornia() -> bool:
    """Check Kornia installation for LoFTR."""
    try:
        import kornia

        print(f"\nKornia Version: {kornia.__version__}")
        return True
    except ImportError:
        print("Kornia is not installed")
        return False


def main() -> int:
    """Run all verification checks."""
    print("=" * 60)
    print("Geo-Rect CUDA Verification Script")
    print("=" * 60)

    checks = [
        ("NVIDIA Driver", check_nvidia_smi),
        ("PyTorch CUDA", check_pytorch_cuda),
        ("Kornia", check_kornia),
    ]

    results = []
    for name, check_func in checks:
        print(f"\n--- {name} Check ---")
        results.append((name, check_func()))

    print("\n" + "=" * 60)
    print("Summary:")
    print("=" * 60)

    all_passed = True
    for name, passed in results:
        status = "PASSED" if passed else "FAILED"
        print(f"  {name}: {status}")
        if not passed:
            all_passed = False

    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())
```

---

### Fase 7: Archivos de Configuraci√≥n Adicionales (30 min)

#### 7.1 Archivo `.gitignore`

```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
.venv/
*.egg-info/
dist/
build/

# Poetry
poetry.lock

# IDE
.vscode/
.idea/
*.swp
*.swo

# Jupyter
.ipynb_checkpoints/
*.ipynb_checkpoints

# Environment
.env
.env.local
*.env

# Data (managed by DVC)
data/raw/*
data/processed/*
data/labeled/*
!data/**/.gitkeep

# Models (managed by DVC)
models/*
!models/.gitkeep

# MLflow
mlruns/
mlflow.db

# Dagster
.dagster/

# Coverage
htmlcov/
.coverage
coverage.xml

# pytest
.pytest_cache/

# mypy
.mypy_cache/

# DVC
/data/**/*.dvc
/models/**/*.dvc

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Temporary
tmp/
temp/
*.tmp
```

#### 7.2 Archivo `.env.example`

```bash
# Google Maps API
GOOGLE_MAPS_API_KEY=your_api_key_here

# GCP Configuration
GCP_PROJECT_ID=geo-rect-prod
GCP_REGION=us-central1
GCS_BUCKET=geo-rect-artifacts

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000

# DVC Remote
DVC_REMOTE=gs://geo-rect-artifacts

# Application
LOG_LEVEL=INFO
DEBUG=false
```

#### 7.3 Archivo `README.md` inicial

```markdown
# Geo-Rect: Sistema H√≠brido de Validaci√≥n Geoespacial

> Sistema de detecci√≥n de discrepancias geom√©tricas y sem√°nticas entre vectores catastrales e im√°genes satelitales usando Computer Vision + Machine Learning.

## üöÄ Quick Start

### Prerrequisitos

- Windows 11
- Python 3.11+
- Poetry >= 1.7.0
- NVIDIA GPU con CUDA 12.4
- Docker Desktop

### Instalaci√≥n

```powershell
# Clonar repositorio
git clone https://github.com/arthuzumbo/geo-rect.git
cd geo-rect

# Instalar dependencias
poetry install --with dev

# Verificar CUDA
poetry run python scripts/verify_cuda.py

# Configurar pre-commit
poetry run pre-commit install

# Copiar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# Levantar servicios auxiliares
docker-compose -f docker/docker-compose.yml up -d
```

### Verificar Instalaci√≥n

```powershell
# Verificar PyTorch con CUDA
poetry run python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"

# Ejecutar tests
poetry run pytest tests/ -v

# Verificar servicios
# MLflow: http://localhost:5000
# Dagster: http://localhost:3000
```

## üìÅ Estructura del Proyecto

```
geo-rect/
‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ acquisition/        # Fase 1: Adquisici√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ alignment/          # Fase 2: Alineaci√≥n CV
‚îÇ   ‚îú‚îÄ‚îÄ classification/     # Fase 3: Clasificaci√≥n ML
‚îÇ   ‚îî‚îÄ‚îÄ api/                # FastAPI backend
‚îú‚îÄ‚îÄ data/                   # Datos (DVC tracked)
‚îú‚îÄ‚îÄ models/                 # Modelos entrenados (DVC tracked)
‚îú‚îÄ‚îÄ notebooks/              # Jupyter notebooks
‚îú‚îÄ‚îÄ tests/                  # Tests unitarios e integraci√≥n
‚îî‚îÄ‚îÄ docs/                   # Documentaci√≥n
```

## üõ†Ô∏è Stack Tecnol√≥gico

- **Deep Learning:** PyTorch 2.5.1 + CUDA 12.4
- **Computer Vision:** OpenCV, Kornia (LoFTR), SAM
- **Machine Learning:** XGBoost, LightGBM, DINOv2
- **Geospatial:** GeoPandas, Shapely, Rasterio
- **MLOps:** DVC, MLflow, Dagster
- **API:** FastAPI, Pydantic

## üìö Documentaci√≥n

- [Arquitectura](docs/architecture.md)
- [API Reference](docs/api_reference.md)
- [Gu√≠a de Contribuci√≥n](CONTRIBUTING.md)

## üìù Licencia

MIT License - ver [LICENSE](LICENSE) para m√°s detalles.

---
**Autor:** Arthur Zizumbo
**Proyecto:** INE - Validaci√≥n Cartogr√°fica
```

---

## üß™ Plan de Pruebas

### Tests de Verificaci√≥n

| ID | Prueba | Comando | Resultado Esperado |
|----|--------|---------|-------------------|
| T1 | Poetry instalado | `poetry --version` | >= 1.7.0 |
| T2 | Entorno virtual creado | `poetry env info` | Python 3.11.x |
| T3 | PyTorch con CUDA | `poetry run python scripts/verify_cuda.py` | All checks PASSED |
| T4 | Pre-commit hooks | `poetry run pre-commit run --all-files` | Passed |
| T5 | Docker services | `docker-compose ps` | mlflow, dagster running |
| T6 | MLflow UI | Abrir http://localhost:5000 | Interfaz visible |
| T7 | Importaciones core | Ver script abajo | Sin errores |

### Script de Verificaci√≥n de Importaciones

```python
"""Test core imports."""

def test_imports():
    # Deep Learning
    import torch
    assert torch.cuda.is_available()

    # Computer Vision
    import cv2
    import kornia

    # Geospatial
    import geopandas
    import shapely
    import rasterio

    # Machine Learning
    import xgboost
    import lightgbm
    import sklearn

    # MLOps
    import mlflow
    import dvc

    # API
    import fastapi
    import pydantic

    print("All imports successful!")


if __name__ == "__main__":
    test_imports()
```

---

## üìä M√©tricas de √âxito

| M√©trica | Criterio | Estado |
|---------|----------|--------|
| Estructura de directorios | Conforme a Cookiecutter + AGENTS.md | ‚¨ú |
| Poetry environment | Python 3.11, todas las dependencias instaladas | ‚¨ú |
| PyTorch CUDA | `torch.cuda.is_available() == True` | ‚¨ú |
| VRAM detectada | RTX 4070 con 8GB | ‚¨ú |
| Pre-commit hooks | Todos los checks pasan | ‚¨ú |
| Docker services | MLflow + Dagster corriendo | ‚¨ú |
| README completo | Instrucciones de setup funcionales | ‚¨ú |

---

## ‚ö†Ô∏è Riesgos y Mitigaciones

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|--------------|---------|------------|
| Conflicto Poetry Python 3.12 vs 3.11 | Media | Alto | Especificar `poetry env use python3.11` expl√≠citamente |
| CUDA version mismatch | Baja | Alto | Usar PyTorch wheel oficial para CUDA 12.4 |
| Docker memory limits | Baja | Medio | Configurar l√≠mites en docker-compose |
| Pre-commit lento | Baja | Bajo | Excluir archivos grandes del check |

---

## üìÖ Cronograma Detallado

| Fase | Tarea | Duraci√≥n | Acumulado |
|------|-------|----------|-----------|
| 1 | Verificaci√≥n prerrequisitos | 30 min | 0:30 |
| 2 | Estructura Cookiecutter | 45 min | 1:15 |
| 3 | Poetry + dependencias | 60 min | 2:15 |
| 4 | Pre-commit hooks | 30 min | 2:45 |
| 5 | Docker Compose | 60 min | 3:45 |
| 6 | Scripts verificaci√≥n | 30 min | 4:15 |
| 7 | Configuraci√≥n adicional | 30 min | 4:45 |
| 8 | Testing y ajustes | 75 min | 6:00 |

**Total estimado:** 6 horas (3 puntos de historia)

---

## üìã Checklist Pre-Implementaci√≥n

- [ ] Verificar espacio en disco (>50GB disponibles)
- [ ] Verificar drivers NVIDIA actualizados
- [ ] Verificar Docker Desktop funcionando
- [ ] Tener API key de Google Maps lista
- [ ] Tener cuenta GCP configurada

---

## üéØ Entregables

1. **Estructura de proyecto** completa seg√∫n especificaci√≥n
2. **pyproject.toml** con todas las dependencias
3. **docker-compose.yml** funcional
4. **Pre-commit hooks** configurados
5. **README.md** con instrucciones de setup
6. **Script de verificaci√≥n** de CUDA
7. **Archivos de configuraci√≥n** (.gitignore, .env.example)

---

## üìù Notas Adicionales

### Sobre PyTorch y CUDA

Se utiliza PyTorch 2.5.1 con CUDA 12.4 (la versi√≥n estable m√°s reciente disponible en los wheels oficiales). La instalaci√≥n se realiza desde el √≠ndice oficial de PyTorch:

```
https://download.pytorch.org/whl/cu124
```

### Sobre la Compatibilidad Python

Aunque Poetry est√° instalado en Python 3.12.6, el proyecto usar√° Python 3.11 para m√°xima compatibilidad con las librer√≠as de ML/CV. Poetry manejar√° esto autom√°ticamente con `poetry env use python3.11`.

### Sobre Cookiecutter

La estructura sigue las convenciones de [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/) pero adaptada para:
- Paradigma Local-First MLOps
- Estructura de 3 fases (acquisition, alignment, classification)
- Convenciones de AGENTS.md del proyecto

---

**Documento creado:** 2025-11-26
**Autor:** GitHub Copilot + Arthur Zizumbo
**Versi√≥n:** 1.0
